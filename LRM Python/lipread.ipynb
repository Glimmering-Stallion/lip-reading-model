{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e3d0dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is an implementation of the model found in this paper:\n",
    "# https://arxiv.org/pdf/1611.01599.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "befdbe2c",
   "metadata": {},
   "source": [
    "# 1: Initial Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e0f226",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install dependencies\n",
    "# pip install command:                  !pip install opencv-python matplotlib imageio gdown tensorflow\n",
    "# pip see installed packages command:   !pip list\n",
    "\n",
    "# create virtual environment (Mac):     python3 -m venv [name]\n",
    "# activate virtual environment (Mac):   source [name]/bin/activate\n",
    "# deactivate virtual environment (Mac): deactivate\n",
    "\n",
    "# add venv to jupyter kernels:          python -m ipykernel install --user --name=lipread --display-name \"Python (lipread)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4eb43fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import os\n",
    "import cv2\n",
    "import gdown\n",
    "import imageio\n",
    "import numpy as np\n",
    "from typing import List\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2fb5da73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prevent out of memory (OOM) errors by setting GPU memory consumption growth\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "try:\n",
    "    tf.config.xperimental.set_memory_growth(physical_devices[0], True)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2557181a",
   "metadata": {},
   "source": [
    "# 2: Data Loading/Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03fcb3eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data directory already exists, downloading skipped.\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists('../data'):\n",
    "    print(\"Data directory not found, downloading...\")\n",
    "    url = 'https://drive.google.com/uc?id=1YlvpDLix3S-U8fd-gqRwPcWXAXm8JwjL'\n",
    "    output = '../data.zip'\n",
    "    gdown.download(url, output, quiet = False)\n",
    "    gdown.extractall('../data.zip', output='../')\n",
    "else:\n",
    "    print(\"Data directory already exists, downloading skipped.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2023d31c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The vocabulary list: ['', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', \"'\", '?', '!', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ' '] (size = 41)\n"
     ]
    }
   ],
   "source": [
    "# create array of every possible character expected to be encountered within annotations\n",
    "vocab = [char for char in \"abcdefghijklmnopqrstuvwxyz'?!0123456789 \"]\n",
    "\n",
    "# create a bidirectional mapping between characters and integers to enable easy conversion between character sequences and their corresponding numerical representations\n",
    "char_to_num = tf.keras.layers.StringLookup(vocabulary = vocab, oov_token = \"\") # convert characters to numbers\n",
    "num_to_char = tf.keras.layers.StringLookup(vocabulary = char_to_num.get_vocabulary(), oov_token = \"\", invert = True) # convert numbers to characters\n",
    "\n",
    "# debugging\n",
    "print(\n",
    "    f\"The vocabulary list: {char_to_num.get_vocabulary()} \"\n",
    "    f\"(size = {char_to_num.vocabulary_size()})\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47b91fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data loading function (takes in a data path and outputs a list of floats)\n",
    "def load_video(path: str) -> List[float]:\n",
    "\n",
    "    cap = cv2.VideoCapture(path) # create a video capture instance\n",
    "\n",
    "    # loop through each frame and store in an array\n",
    "    frames = []\n",
    "    for _ in range(int(cap.get(cv2.CAP_PROP_FRAME_COUNT))):\n",
    "        _, frame = cap.read() # read in video frame data\n",
    "        frame = tf.image.rgb_to_grayscale(frame) # convert from RGB to grayscale to reduce amount of data to be processed\n",
    "        frames.append(frame[190:236, 80:220, :]) # static slicing for trimming down frame to isolate to mouth region\n",
    "    cap.release()\n",
    "\n",
    "    # standardization of frame data through Z-score normalization\n",
    "    mean = tf.math.reduce_mean(frames) # calculate mean\n",
    "    std = tf.math.reduce_std(tf.cast(frames, tf.float32)) # calculate standard deviation\n",
    "    return tf.cast((frames - mean), tf.float32) / std # return standardized frame data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c7bd57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to load alignments (takes in a data path and outputs a list of strings)\n",
    "def load_alignments(path: str) -> List[str]:\n",
    "\n",
    "    # read in lines\n",
    "    with open(path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    # loop through each line\n",
    "    tokens = []\n",
    "    for line in lines:\n",
    "        line = line.split() # split line into a list of elements by each space\n",
    "        # append third element of line to an array (ignore any lines that contain 'sil')\n",
    "        if line[2] != 'sil':\n",
    "            tokens = [*tokens, line[2]]\n",
    "            \n",
    "    return char_to_num(tf.reshape(tf.strings.unicode_split(tokens, input_encoding = 'UTF-8'), (-1)))[1:] # return the numerical values of characters found in the line elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8da8b603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to load data (takes in a data path and outputs frames and alignments)\n",
    "def load_data(path: str):\n",
    "    path = bytes.decode(path.numpy())\n",
    "\n",
    "    file_name = path.split('/')[-1].split('.')[0] # file name splitting for Mac\n",
    "    # file_name = path.split('\\\\')[-1].split('.')[0] # file name splitting for Windows\n",
    "\n",
    "    video_path = os.path.join('../data', 's1', f'{file_name}.mpg')\n",
    "    alignment_path = os.path.join('../data', 'alignments', 's1', f'{file_name}.align')\n",
    "\n",
    "    frames = load_video(video_path)\n",
    "    alignments = load_alignments(alignment_path)\n",
    "\n",
    "    return frames, alignments # return frames (75 frames x 46px height x 140px width x 1 color channel) and alignments (21 tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9971fc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'n', 'b', 'l', 'u', 'e', 'a', 't', 'l', 's', 'i', 'x', 'n', 'o', 'w']\n"
     ]
    }
   ],
   "source": [
    "# debugging\n",
    "test_path = '../data/s1/bbal6n.mpg'\n",
    "test_frames, test_alignments = load_data(tf.convert_to_tensor(test_path))\n",
    "[plt.imshow(test_frames[f_index]) and plt.show() for f_index in range(1)] # display first n frames as plots\n",
    "print([bytes.decode(x) for x in num_to_char(test_alignments.numpy()).numpy()]) # display corresponding alignment as characters in an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "509f450c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mappable processing function (takes in a data path and outputs frames and alignments as a tuple of tensors)\n",
    "def mappable_function(path: str) -> List[str]:\n",
    "    result = tf.py_function(load_data, [path], (tf.float32, tf.int64)) # wrap load_data function as a TensorFlow operation\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55d3cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = tf.data.Dataset.list_files('../data/s1/*.mpg') # obtain all video files in given directory\n",
    "data = data.shuffle(500, reshuffle_each_iteration = False) # shuffle an amount of data specified by the cache size\n",
    "data = data.map(mappable_function) # transforms the dataset of file paths into a new dataset\n",
    "data = data.padded_batch(2, padded_shapes = ([75, None, None, None], [40])) # create new TensorFlow dataset containing batches of 2 elements (the frames tensor within each batch is padded to have a fixed size of 75 frames)\n",
    "data = data.prefetch(tf.data.AUTOTUNE) # fetch data from next iteration while current iteration is still being processed which mitigates bottlenecking (the argument 'tf.data.AUTOTUNE' is a special value that allows TensorFlow to automatically tune the prefetching buffer size based on available system resources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "888c728b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train/test data partitioning\n",
    "train = data.take(450)\n",
    "test = data.skip(450)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ccdc3a0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b'etredatufourplease'>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# debugging\n",
    "sample_data = data.as_numpy_iterator().next(); sample_data[0] # obtain frames from data\n",
    "# imageio.mimsave('./animation.gif', test_data[0][1], duration = 100) # create an animated GIF file from the sequence of frames\n",
    "tf.strings.reduce_join([num_to_char(word) for word in sample_data[1][0]]) # display second alignment in batch as characters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d8e312",
   "metadata": {},
   "source": [
    "# 4: Deep Neural Network Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "067cc9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv3D, LSTM, Dense, Dropout, Bidirectional, MaxPool3D, Activation, Reshape, SpatialDropout3D, BatchNormalization, TimeDistributed, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7b429341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv3d (Conv3D)             (None, 75, 46, 140, 128   3584      \n",
      "                             )                                   \n",
      "                                                                 \n",
      " activation (Activation)     (None, 75, 46, 140, 128   0         \n",
      "                             )                                   \n",
      "                                                                 \n",
      " max_pooling3d (MaxPooling3  (None, 75, 23, 70, 128)   0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv3d_1 (Conv3D)           (None, 75, 23, 70, 256)   884992    \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 75, 23, 70, 256)   0         \n",
      "                                                                 \n",
      " max_pooling3d_1 (MaxPoolin  (None, 75, 11, 35, 256)   0         \n",
      " g3D)                                                            \n",
      "                                                                 \n",
      " conv3d_2 (Conv3D)           (None, 75, 11, 35, 75)    518475    \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 75, 11, 35, 75)    0         \n",
      "                                                                 \n",
      " max_pooling3d_2 (MaxPoolin  (None, 75, 5, 17, 75)     0         \n",
      " g3D)                                                            \n",
      "                                                                 \n",
      " time_distributed (TimeDist  (None, 75, 6375)          0         \n",
      " ributed)                                                        \n",
      "                                                                 \n",
      " bidirectional (Bidirection  (None, 75, 256)           6660096   \n",
      " al)                                                             \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 75, 256)           0         \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirecti  (None, 75, 256)           394240    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 75, 256)           0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 75, 41)            10537     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8471924 (32.32 MB)\n",
      "Trainable params: 8471924 (32.32 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "1/1 [==============================] - 3s 3s/step\n"
     ]
    }
   ],
   "source": [
    "# neural network architecture\n",
    "def create_model(vocab_size: int) -> Sequential:\n",
    "    model = Sequential() # instantiation of model\n",
    "\n",
    "    # first convolution (128 convolution kernels, 3x3x3 kernel size, frame data shape, padding is same to preserve input shape)\n",
    "    model.add(Conv3D(128, 3, input_shape = (75, 46, 140, 1), padding = 'same'))\n",
    "    model.add(Activation('relu')) # provide non-linearity outputs using ReLU function\n",
    "    model.add(MaxPool3D((1, 2, 2))) # condense output down through max pooling\n",
    "\n",
    "    # second convolution (256 convolution kernels, 3x3x3 kernel size, frame data shape, padding is same to preserve input shape)\n",
    "    model.add(Conv3D(256, 3, padding = 'same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPool3D((1, 2, 2)))\n",
    "\n",
    "    # third convolution (75 convolution kernels, 3x3x3 kernel size, frame data shape, padding is same to preserve input shape)\n",
    "    model.add(Conv3D(75, 3, padding = 'same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPool3D((1, 2, 2)))\n",
    "\n",
    "    model.add(TimeDistributed(Reshape((-1,)))) # independently apply flatten operation on every temporal slice of input\n",
    "\n",
    "    # first bidirectional LSTM (128 LSTM hidden units, initialize weights with orthogonal matrices, return a sequence of outputs instead of a single final output)\n",
    "    model.add(Bidirectional(LSTM(128, kernel_initializer = 'Orthogonal', return_sequences = True)))\n",
    "    model.add(Dropout(0.5)) # drop out 50% of the units\n",
    "\n",
    "    # second bidirectional LSTM\n",
    "    model.add(Bidirectional(LSTM(128, kernel_initializer = 'Orthogonal', return_sequences = True)))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    # fully connected dense layer (number of neurons in output layer equal to vocab size, weights of neurons initialized with he_normal initialization, activation function for output layer as softmax)\n",
    "    model.add(Dense(vocab_size, kernel_initializer = 'he_normal', activation = 'softmax'))\n",
    "\n",
    "    return model\n",
    "\n",
    "# debugging\n",
    "model = create_model(char_to_num.vocabulary_size())\n",
    "model.summary()\n",
    "y_hat = model.predict(sample_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8dc2026",
   "metadata": {},
   "source": [
    "# 5: Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8e2cdf29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for learning rate scheduling\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch < 30:\n",
    "        return lr # output learning rate if epochs is below certain threshold\n",
    "    else:\n",
    "        return lr * tf.math.exp(-0.1) # otherwise reduce the learning rate using exponential function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2cdd0ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for calculating loss between a continuous (unsegmented) time series and a target sequence\n",
    "def CTCLoss(y_true, y_pred):\n",
    "    batch_len = tf.cast(tf.shape(y_true)[0], dtype = 'int64') # get the number of examples in the batch\n",
    "    input_len = tf.cast(tf.shape(y_pred)[1], dtype = 'int64') # get the length of the predicted sequence\n",
    "    label_len = tf.cast(tf.shape(y_true)[1], dtype = 'int64') # get the length of the true sequence\n",
    "\n",
    "    # expand input_len and label_len to match the batch size\n",
    "    input_len = input_len * tf.ones(shape = (batch_len, 1), dtype = 'int64')\n",
    "    label_len = label_len * tf.ones(shape = (batch_len, 1), dtype = 'int64')\n",
    "\n",
    "    # compute and return the CTC loss using tf.keras.backend.ctc_batch_cost\n",
    "    loss = tf.keras.backend.ctc_batch_cost(y_true, y_pred, input_len, label_len)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a45a6be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom callback class that generates and prints examples after each epoch during training\n",
    "class ProduceExample(tf.keras.callbacks.Callback):\n",
    "\n",
    "    # constructor that initializes callback with a dataset iterator\n",
    "    def __init__(self, dataset) -> None:\n",
    "        self.dataset = dataset.as_numpy_iterator()\n",
    "\n",
    "    # function called at the end of each training epoch to generate and print examples\n",
    "    def on_epoch_end(self, epoch, logs = None) -> None:\n",
    "        data = self.dataset.next() # get the next batch of data from dataset\n",
    "        y_hat = self.model.predict(data[0]) # predict sequences using model\n",
    "        decoded = tf.keras.backend.ctc_decode(y_hat, [75, 75], greedy = False)[0][0].numpy() # decodes predicted sequences using CTC decoding\n",
    "\n",
    "        # loop through each example in the batch and print original ground truth sequences along with predicted sequences\n",
    "        # for x in range(len(y_hat)):\n",
    "        #     print('Original: ', tf.string.reduce_join([vocab[word] + ' ' for word in data[1][x]])).numpy().decode('utf-8')\n",
    "        #     print('Prediction: ', tf.string.reduce_join([vocab[word] + ' ' for word in decoded[x]])).numpy().decode('utf-8')\n",
    "        #     print('~' * 100) # print separator line after each example\n",
    "\n",
    "        # loop through each example in the batch and print original ground truth sequences along with predicted sequences\n",
    "        for x in range(len(y_hat)):\n",
    "            # convert original sequence to string format\n",
    "            str_tensor_original = tf.constant([vocab[word] + ' ' for word in data[1][x]])\n",
    "            str_original = tf.strings.reduce_join(str_tensor_original).numpy().decode('utf-8')\n",
    "            print('Original: ', str_original)\n",
    "\n",
    "            # convert predicted sequence to string format\n",
    "            str_tensor_prediction = tf.constant([vocab[word] + ' ' for word in decoded[x]])\n",
    "            str_prediction = tf.strings.reduce_join(str_tensor_prediction).numpy().decode('utf-8')\n",
    "            print('Prediction: ', str_prediction)\n",
    "\n",
    "            # separator line after each example\n",
    "            print('~' * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ed303fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # compile model\n",
    "# model.compile(optimizer = Adam(learning_rate = 0.0001), loss = CTCLoss)\n",
    "\n",
    "# # define callbacks\n",
    "# checkpoint_callback = ModelCheckpoint('models/model.weights.h5', monitor = 'loss', save_weights_only = True) # responsible for saving the model's weights during training\n",
    "# schedule_callback = LearningRateScheduler(scheduler) # allows for scheduling changes to the learning rate during training\n",
    "# example_callback = ProduceExample(data) # responsible for generating and printing examples at the end of each epoch during training\n",
    "\n",
    "# # train model on given dataset for specified number of epochs\n",
    "# model.fit(train, validation_data = test, epochs = 100, callbacks = [checkpoint_callback, schedule_callback, example_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e288e90",
   "metadata": {},
   "source": [
    "# 5: Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0305db9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_weights('models/checkpoint')\n",
    "# model.save_weights('models/model.weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "be5ef397",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x30d88ce50>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract model checkpoints externally\n",
    "# url = 'https://drive.google.com/uc?id=1vWscXs4Vt0a_1IH1-ct2TCgXAZT-N3_Y'\n",
    "# output = 'checkpoints.zip'\n",
    "# gdown.download(url, output, quiet = False)\n",
    "# gdown.extractall('checkpoints.zip', 'models')\n",
    "\n",
    "# load checkpoints locally\n",
    "# model.load_weights('models/model.weights.h5')\n",
    "model.load_weights('models/checkpoint')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a7887eee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[mpeg1video @ 0x30dd184c0] ac-tex damaged at 22 17\n",
      "[mpeg1video @ 0x30dd184c0] Warning MVs not available\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "REAL TEXT ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "PREDICTIONS ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=string, numpy=b'bin9green9by9b9oe9sooon'>,\n",
       " <tf.Tensor: shape=(), dtype=string, numpy=b'lay9blue9by9e9three9again'>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# debugging\n",
    "test_data = test.as_numpy_iterator().next()\n",
    "y_hat = model.predict(test_data[0])\n",
    "decoded = tf.keras.backend.ctc_decode(y_hat, input_length = [75, 75], greedy = True)[0][0].numpy()\n",
    "\n",
    "# actual text\n",
    "print('REAL TEXT', '~' * 100)\n",
    "[tf.strings.reduce_join([num_to_char(word) for word in sentence]) for sentence in test_data[1]]\n",
    "\n",
    "# predicted text\n",
    "print('PREDICTIONS', '~' * 100)\n",
    "[tf.strings.reduce_join([num_to_char(word) for word in sentence]) for sentence in decoded]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "56945c52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "ACTUAL TEXT: etwhitewithininesoon\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "PREDICTED TEXT: set white with i nine soon\n"
     ]
    }
   ],
   "source": [
    "sample = load_data(tf.convert_to_tensor('./data/s1/swwi9s.mpg')) # load in new video data\n",
    "y_hat = model.predict(tf.expand_dims(sample[0], axis = 0)) # perform prediction\n",
    "decoded = tf.keras.backend.ctc_decode(y_hat, input_length = [75], greedy = True)[0][0].numpy() # decode prediction\n",
    "\n",
    "# actual text\n",
    "print('~' * 100)\n",
    "actual_text = tf.strings.reduce_join([num_to_char(word) for word in sample[1]])\n",
    "print('ACTUAL TEXT:', actual_text.numpy().decode('utf-8'))\n",
    "\n",
    "# predicted text\n",
    "print('~' * 100)\n",
    "predicted_text = tf.strings.reduce_join([num_to_char(word) for word in decoded])\n",
    "print('PREDICTED TEXT:', ' '.join(predicted_text.numpy().decode('utf-8').split('9')))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lipread",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
